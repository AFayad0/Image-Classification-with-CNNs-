{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AFayad0/Image-Classification-with-CNNs-/blob/main/Knowledge_Discovery_Homework1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet Model with Cropping Images\n"
      ],
      "metadata": {
        "id": "XR_2GBc-Rf9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import torch\n",
        "import torchvision \n",
        "import os\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import copy\n",
        "from torch.optim import lr_scheduler\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import cv2\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-05-23T10:18:11.043429Z",
          "iopub.execute_input": "2023-05-23T10:18:11.044245Z",
          "iopub.status.idle": "2023-05-23T10:18:14.553383Z",
          "shell.execute_reply.started": "2023-05-23T10:18:11.044195Z",
          "shell.execute_reply": "2023-05-23T10:18:14.551461Z"
        },
        "trusted": true,
        "id": "x0lY9a6BMhV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(\"/kaggle/input/aiunict-2023/train/01/01_002.png\")\n",
        "# Create a background subtractor\n",
        "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "# Apply the background subtractor to the image\n",
        "mask = bg_subtractor.apply(img)\n",
        "\n",
        "# Remove the background from the original image using the mask\n",
        "img_without_bg = cv2.bitwise_and(img, img, mask=mask)\n",
        "\n",
        "# Save the result\n",
        "cv2.imwrite(\"5.png\", img_without_bg)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-23T10:18:49.093315Z",
          "iopub.execute_input": "2023-05-23T10:18:49.094142Z",
          "iopub.status.idle": "2023-05-23T10:18:49.201800Z",
          "shell.execute_reply.started": "2023-05-23T10:18:49.094086Z",
          "shell.execute_reply": "2023-05-23T10:18:49.200696Z"
        },
        "trusted": true,
        "id": "6MgrN1XgMhV-",
        "outputId": "15869230-c937-4b73-8e3b-e234d49f33a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 2,
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####### MORE CENTERED CROP #########\n",
        "'''\n",
        "# load csv file with image coordinates\n",
        "csv_file = '/kaggle/input/aiunict-2023/train.csv'\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# path to original images\n",
        "img_folder = '/kaggle/input/aiunict-2023/train'\n",
        "\n",
        "# path to new cropped images\n",
        "cropped_folder = '/kaggle/working/train'\n",
        "\n",
        "# create folders for cropped images if they don't exist\n",
        "if not os.path.exists(cropped_folder):\n",
        "    os.makedirs(cropped_folder)\n",
        "\n",
        "# loop through rows in the dataframe\n",
        "for index, row in df.iterrows():\n",
        "    # get image name and coordinates from dataframe\n",
        "    img_name = row['image']\n",
        "    x1, y1, x2, y2 = row['x1'], row['y1'], row['x2'], row['y2']\n",
        "    img_class = row['class']\n",
        "    \n",
        "    if(x1 < 1):\n",
        "        continue\n",
        "        \n",
        "    # calculate center of bounding box\n",
        "    center_x = (x1 + x2) // 2\n",
        "    center_y = (y1 + y2) // 2\n",
        "    \n",
        "    # adjust coordinates for cropping\n",
        "    crop_width = int((x2 - x1) * 0.5)  # crop more than half of the image\n",
        "    crop_height = int((y2 - y1) * 0.5)  # crop more than half of the image\n",
        "    crop_x1 = center_x - crop_width // 2\n",
        "    crop_y1 = center_y - crop_height // 2\n",
        "    crop_x2 = center_x + crop_width // 2\n",
        "    crop_y2 = center_y + crop_height // 2    \n",
        "    \n",
        "    \n",
        " \n",
        "        \n",
        "    # path to original image and new cropped image\n",
        "    img_path = os.path.join(img_folder, img_name)\n",
        "    cropped_path = os.path.join(cropped_folder, f'0{img_class}')\n",
        "\n",
        "    # read original image and crop it\n",
        "    img = cv2.imread(img_path)\n",
        "    cropped_img = img[crop_y1:crop_y2, crop_x1:crop_x2]\n",
        "\n",
        "    # write cropped image to file\n",
        "    if not os.path.exists(cropped_path):\n",
        "        os.makedirs(cropped_path)\n",
        "    cv2.imwrite(os.path.join(cropped_path, img_name.split('/')[-1]), cropped_img)\n",
        "'''\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "KtVUDgXyMhWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#try only class 0\n",
        "'''\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# load csv file with image coordinates\n",
        "csv_file = '/kaggle/input/aiunict-2023/train.csv'\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# path to original images\n",
        "img_folder = '/kaggle/input/aiunict-2023/train'\n",
        "\n",
        "# path to new images\n",
        "new_folder = '/kaggle/working/train'\n",
        "\n",
        "# create folders for new images if they don't exist\n",
        "if not os.path.exists(new_folder):\n",
        "    os.makedirs(new_folder)\n",
        "\n",
        "# loop through rows in the dataframe\n",
        "for index, row in df.iterrows():\n",
        "    # get image name and coordinates from dataframe\n",
        "    img_name = row['image']\n",
        "    x1, y1, x2, y2 = row['x1'], row['y1'], row['x2'], row['y2']\n",
        "    img_class = row['class']\n",
        "\n",
        "    # read original image\n",
        "    img = cv2.imread(os.path.join(img_folder, img_name))\n",
        "    \n",
        "    # create mask with zeros\n",
        "    mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
        "\n",
        "    # draw bounding box on mask\n",
        "    cv2.rectangle(mask, (x1, y1), (x2, y2), (255, 255, 255), -1)\n",
        "\n",
        "    # blur and desaturate background outside of bounding box\n",
        "    blur_radius = 99\n",
        "    img_blurred = cv2.GaussianBlur(img, (blur_radius, blur_radius), 0)\n",
        "    mask_inv = cv2.bitwise_not(mask)\n",
        "    img_desaturated = cv2.cvtColor(img_blurred, cv2.COLOR_BGR2GRAY)\n",
        "    img_desaturated = cv2.cvtColor(img_desaturated, cv2.COLOR_GRAY2BGR)\n",
        "    img_background = cv2.bitwise_and(img_blurred, img_blurred, mask=mask_inv)\n",
        "    img_background = cv2.cvtColor(img_background, cv2.COLOR_BGR2GRAY)\n",
        "    img_background = cv2.cvtColor(img_background, cv2.COLOR_GRAY2BGR)\n",
        "    \n",
        "    # combine background and foreground inside of bounding box\n",
        "    img_result = cv2.bitwise_or(img_background, img)\n",
        "    \n",
        "    if img_class != 0:\n",
        "        img_result = img\n",
        "    \n",
        "    # save new image\n",
        "    new_folder_class = os.path.join(new_folder, f'0{img_class}')\n",
        "    if not os.path.exists(new_folder_class):\n",
        "        os.makedirs(new_folder_class)\n",
        "    cv2.imwrite(os.path.join(new_folder_class, img_name.split('/')[-1]), img_result)\n",
        "'''"
      ],
      "metadata": {
        "trusted": true,
        "id": "j4OI049oMhWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Working BLACK Background\n",
        "\n",
        "\n",
        "# load csv file with image coordinates\n",
        "csv_file = '/kaggle/input/aiunict-2023/train.csv'\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# path to original images\n",
        "img_folder = '/kaggle/input/aiunict-2023/train'\n",
        "\n",
        "# path to new images\n",
        "new_folder = '/kaggle/working/train'\n",
        "\n",
        "# create folders for new images if they don't exist\n",
        "if not os.path.exists(new_folder):\n",
        "    os.makedirs(new_folder)\n",
        "\n",
        "# loop through rows in the dataframe\n",
        "for index, row in df.iterrows():\n",
        "    # get image name and coordinates from dataframe\n",
        "    img_name = row['image']\n",
        "    x1, y1, x2, y2 = row['x1'], row['y1'], row['x2'], row['y2']\n",
        "    img_class = row['class']\n",
        "    \n",
        "    # read original image\n",
        "    img_path = os.path.join(img_folder, img_name)\n",
        "    img = cv2.imread(img_path)\n",
        "\n",
        "    # create mask\n",
        "    mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
        "    mask[y1:y2, x1:x2] = 255\n",
        "\n",
        "    # apply mask to original image to color the area inside the bounding box\n",
        "    new_img = cv2.bitwise_and(img, img, mask=mask)\n",
        "\n",
        "    #if img_class != 0:\n",
        "        #new_img = img\n",
        "    \n",
        "    # write new image to file\n",
        "    new_path = os.path.join(new_folder, f'0{img_class}')\n",
        "    if not os.path.exists(new_path):\n",
        "        os.makedirs(new_path)\n",
        "    cv2.imwrite(os.path.join(new_path, img_name.split('/')[-1]), new_img)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-23T10:19:15.921450Z",
          "iopub.execute_input": "2023-05-23T10:19:15.922284Z",
          "iopub.status.idle": "2023-05-23T10:19:46.014734Z",
          "shell.execute_reply.started": "2023-05-23T10:19:15.922243Z",
          "shell.execute_reply": "2023-05-23T10:19:46.013388Z"
        },
        "trusted": true,
        "id": "LurnK21XMhWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('/kaggle/input/aiunict-2023/train.csv') as csv_file:\n",
        " #   csv_reader = csv.reader(csv_file)\n",
        " #   rows = list(csv_reader)"
      ],
      "metadata": {
        "trusted": true,
        "id": "hXD_1ygGMhWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import shutil\n",
        "#shutil.rmtree('/kaggle/working/test')"
      ],
      "metadata": {
        "trusted": true,
        "id": "6hM4bPU4MhWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify transforms \n",
        "transformations = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.Resize(224),\n",
        "    #transforms.Resize(255),\n",
        "    #transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-23T10:19:46.045700Z",
          "iopub.execute_input": "2023-05-23T10:19:46.046190Z",
          "iopub.status.idle": "2023-05-23T10:19:46.053295Z",
          "shell.execute_reply.started": "2023-05-23T10:19:46.046139Z",
          "shell.execute_reply": "2023-05-23T10:19:46.051932Z"
        },
        "trusted": true,
        "id": "3gv0JKQiMhWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in each dataset and apply transformations \n",
        "dataset = datasets.ImageFolder(\"/kaggle/working/train/\", transform = transformations)\n",
        "len(dataset)\n",
        "train_set, val_set = torch.utils.data.random_split(dataset, [1300, 300])\n",
        "print(len(train_set), len(val_set))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-23T10:19:46.055305Z",
          "iopub.execute_input": "2023-05-23T10:19:46.055768Z",
          "iopub.status.idle": "2023-05-23T10:19:46.098085Z",
          "shell.execute_reply.started": "2023-05-23T10:19:46.055729Z",
          "shell.execute_reply": "2023-05-23T10:19:46.096908Z"
        },
        "trusted": true,
        "id": "ivsSDclDMhWC",
        "outputId": "51a405fb-fb84-4d11-bdc2-378d5efebc3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "1300 300\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "fp731IHnMhWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Put into a Dataloader using torch library\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size =64, shuffle=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-23T10:19:46.099961Z",
          "iopub.execute_input": "2023-05-23T10:19:46.100684Z",
          "iopub.status.idle": "2023-05-23T10:19:46.107054Z",
          "shell.execute_reply.started": "2023-05-23T10:19:46.100634Z",
          "shell.execute_reply": "2023-05-23T10:19:46.106069Z"
        },
        "trusted": true,
        "id": "1lNmTQYRMhWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders = {'train': train_loader,\n",
        "               'val': val_loader}\n",
        "\n",
        "dataset_sizes = {'train': len(train_set),\n",
        "               'val': len(val_set)}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-23T10:19:46.109301Z",
          "iopub.execute_input": "2023-05-23T10:19:46.109701Z",
          "iopub.status.idle": "2023-05-23T10:19:46.118837Z",
          "shell.execute_reply.started": "2023-05-23T10:19:46.109653Z",
          "shell.execute_reply": "2023-05-23T10:19:46.117614Z"
        },
        "trusted": true,
        "id": "e2x82R7ZMhWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-23T10:19:46.120751Z",
          "iopub.execute_input": "2023-05-23T10:19:46.121159Z",
          "iopub.status.idle": "2023-05-23T10:19:46.138521Z",
          "shell.execute_reply.started": "2023-05-23T10:19:46.121123Z",
          "shell.execute_reply": "2023-05-23T10:19:46.137352Z"
        },
        "trusted": true,
        "id": "z_RoFDJsMhWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title(f'predicted: {class_names[preds[j]]}')\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-23T10:19:49.611006Z",
          "iopub.execute_input": "2023-05-23T10:19:49.612046Z",
          "iopub.status.idle": "2023-05-23T10:19:49.623365Z",
          "shell.execute_reply.started": "2023-05-23T10:19:49.611995Z",
          "shell.execute_reply": "2023-05-23T10:19:49.622168Z"
        },
        "trusted": true,
        "id": "P50PeouVMhWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_ft = models.resnet50(pretrained=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "model_ft.fc = nn.Linear(num_ftrs, 8)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-23T10:20:01.529942Z",
          "iopub.execute_input": "2023-05-23T10:20:01.530656Z",
          "iopub.status.idle": "2023-05-23T10:20:05.801715Z",
          "shell.execute_reply.started": "2023-05-23T10:20:01.530613Z",
          "shell.execute_reply": "2023-05-23T10:20:05.800630Z"
        },
        "trusted": true,
        "id": "gl8CxfraMhWD",
        "outputId": "743f9ebf-121a-4f5f-ee20-e45ea7a24fad",
        "colab": {
          "referenced_widgets": [
            "a84fb58e92854b0c909ff5b3c5c9f54e"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n/opt/conda/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0.00/97.8M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a84fb58e92854b0c909ff5b3c5c9f54e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-23T10:20:10.571411Z",
          "iopub.execute_input": "2023-05-23T10:20:10.572220Z",
          "iopub.status.idle": "2023-05-23T10:22:44.782617Z",
          "shell.execute_reply.started": "2023-05-23T10:20:10.572180Z",
          "shell.execute_reply": "2023-05-23T10:22:44.781387Z"
        },
        "trusted": true,
        "id": "ARai_faCMhWD",
        "outputId": "027c37bf-c060-4514-d6ab-885b0e2f0ae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 0/9\n----------\ntrain Loss: 0.5722 Acc: 0.8223\nval Loss: 8.0796 Acc: 0.3367\n\nEpoch 1/9\n----------\ntrain Loss: 0.1767 Acc: 0.9515\nval Loss: 0.7277 Acc: 0.8467\n\nEpoch 2/9\n----------\ntrain Loss: 0.1761 Acc: 0.9500\nval Loss: 0.3601 Acc: 0.8767\n\nEpoch 3/9\n----------\ntrain Loss: 0.2141 Acc: 0.9462\nval Loss: 0.9821 Acc: 0.7433\n\nEpoch 4/9\n----------\ntrain Loss: 0.1562 Acc: 0.9454\nval Loss: 0.0788 Acc: 0.9733\n\nEpoch 5/9\n----------\ntrain Loss: 0.1596 Acc: 0.9546\nval Loss: 0.6823 Acc: 0.8200\n\nEpoch 6/9\n----------\ntrain Loss: 0.1310 Acc: 0.9638\nval Loss: 0.2502 Acc: 0.9433\n\nEpoch 7/9\n----------\ntrain Loss: 0.0673 Acc: 0.9831\nval Loss: 0.0450 Acc: 0.9867\n\nEpoch 8/9\n----------\ntrain Loss: 0.0255 Acc: 0.9954\nval Loss: 0.0246 Acc: 0.9967\n\nEpoch 9/9\n----------\ntrain Loss: 0.0229 Acc: 0.9962\nval Loss: 0.0340 Acc: 0.9900\n\nTraining complete in 2m 34s\nBest val Acc: 0.996667\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Process the image\n",
        "def process_image(image_path):\n",
        "    # Load Image\n",
        "    img = Image.open(image_path)\n",
        "    \n",
        "    # Get the dimensions of the image\n",
        "    width, height = img.size\n",
        "    \n",
        "    # Resize by keeping the aspect ratio, but changing the dimension\n",
        "    # so the shortest size is 255px\n",
        "    img = img.resize((255, int(255*(height/width))) if width < height else (int(255*(width/height)), 255))\n",
        "    \n",
        "    # Get the dimensions of the new image size\n",
        "    width, height = img.size\n",
        "    \n",
        "    # Set the coordinates to do a center crop of 224 x 224\n",
        "    #left = (width - 224)/2\n",
        "    #top = (height - 224)/2\n",
        "    #right = (width + 224)/2\n",
        "    #bottom = (height + 224)/2\n",
        "    #img = img.crop((left, top, right, bottom))\n",
        "    \n",
        "    # Turn image into numpy array\n",
        "    img = np.array(img)\n",
        "    \n",
        "    # Make the color channel dimension first instead of last\n",
        "    img = img.transpose((2, 0, 1))\n",
        "    \n",
        "    # Make all values between 0 and 1\n",
        "    img = img/255\n",
        "    \n",
        "    # Normalize based on the preset mean and standard deviation\n",
        "    img[0] = (img[0] - 0.485)/0.229\n",
        "    img[1] = (img[1] - 0.456)/0.224\n",
        "    img[2] = (img[2] - 0.406)/0.225\n",
        "    \n",
        "    # Add a fourth dimension to the beginning to indicate batch size\n",
        "    img = img[np.newaxis,:]\n",
        "    \n",
        "    # Turn into a torch tensor\n",
        "    image = torch.from_numpy(img)\n",
        "    image = image.float()\n",
        "    return image"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-23T10:23:14.751230Z",
          "iopub.execute_input": "2023-05-23T10:23:14.751736Z",
          "iopub.status.idle": "2023-05-23T10:23:14.762754Z",
          "shell.execute_reply.started": "2023-05-23T10:23:14.751699Z",
          "shell.execute_reply": "2023-05-23T10:23:14.761351Z"
        },
        "trusted": true,
        "id": "2rQq0t1PMhWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the model to predict the label\n",
        "def predict(image, model):\n",
        "    # Pass the image through the model\n",
        "    output = model.forward(image)\n",
        "    \n",
        "    # Reverse the log function in the output\n",
        "    output = torch.exp(output)\n",
        "    \n",
        "    # Get the top predicted class, and the output percentage for\n",
        "    # that class\n",
        "    probs, classes = output.topk(1, dim=1)\n",
        "    return probs.item(), classes.item()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-23T10:23:25.199265Z",
          "iopub.execute_input": "2023-05-23T10:23:25.199691Z",
          "iopub.status.idle": "2023-05-23T10:23:25.208847Z",
          "shell.execute_reply.started": "2023-05-23T10:23:25.199653Z",
          "shell.execute_reply": "2023-05-23T10:23:25.207657Z"
        },
        "trusted": true,
        "id": "aorkRD8GMhWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show Image\n",
        "def show_image(image):\n",
        "    # Convert image to numpy\n",
        "    image = image.numpy()\n",
        "    \n",
        "    # Un-normalize the image\n",
        "    image[0] = image[0] * 0.226 + 0.445\n",
        "    \n",
        "    # Print the image\n",
        "    fig = plt.figure(figsize=(25, 4))\n",
        "    plt.imshow(np.transpose(image[0], (1, 2, 0)))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-23T10:23:29.092186Z",
          "iopub.execute_input": "2023-05-23T10:23:29.093834Z",
          "iopub.status.idle": "2023-05-23T10:23:29.100636Z",
          "shell.execute_reply.started": "2023-05-23T10:23:29.093777Z",
          "shell.execute_reply": "2023-05-23T10:23:29.099536Z"
        },
        "trusted": true,
        "id": "TalnRVjgMhWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Working BLACK Background on TEST IMAGES\n",
        "\n",
        "\n",
        "# load csv file with image coordinates\n",
        "csv_file = '/kaggle/input/aiunict-2023/test.csv'\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# path to original images\n",
        "img_folder = '/kaggle/input/aiunict-2023/test'\n",
        "\n",
        "# path to new cropped images\n",
        "cropped_folder = '/kaggle/working/test'\n",
        "\n",
        "# create folders for new images if they don't exist\n",
        "if not os.path.exists(cropped_folder):\n",
        "    os.makedirs(cropped_folder)\n",
        "\n",
        "# loop through rows in the dataframe\n",
        "for index, row in df.iterrows():\n",
        "    # get image name and coordinates from dataframe\n",
        "    img_name = row['image']\n",
        "    x1, y1, x2, y2 = row['x1'], row['y1'], row['x2'], row['y2']\n",
        "    #img_class = row['class']\n",
        "    \n",
        "    # read original image\n",
        "    img_path = os.path.join(img_folder, img_name)\n",
        "    img = cv2.imread(img_path)\n",
        "\n",
        "    # create mask\n",
        "    mask = np.zeros(img.shape[:2], dtype=np.uint8)\n",
        "    mask[y1:y2, x1:x2] = 255\n",
        "\n",
        "    # apply mask to original image to color the area inside the bounding box\n",
        "    new_img = cv2.bitwise_and(img, img, mask=mask)\n",
        "\n",
        "    #if img_class != 0:\n",
        "        #new_img = img\n",
        "    \n",
        "    # write new image to file\n",
        "    new_path = os.path.join(cropped_folder)\n",
        "    if not os.path.exists(new_path):\n",
        "        os.makedirs(new_path)\n",
        "    cv2.imwrite(os.path.join(new_path, img_name.split('/')[-1]), new_img)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-23T10:23:39.411722Z",
          "iopub.execute_input": "2023-05-23T10:23:39.412125Z",
          "iopub.status.idle": "2023-05-23T10:23:55.551054Z",
          "shell.execute_reply.started": "2023-05-23T10:23:39.412090Z",
          "shell.execute_reply": "2023-05-23T10:23:55.549874Z"
        },
        "trusted": true,
        "id": "89Rkm1cMMhWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### MORE CENTERED TEST CROP ##########\n",
        "\n",
        "# load csv file with image coordinates\n",
        "csv_file = '/kaggle/input/aiunict-2023/test.csv'\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# path to original images\n",
        "img_folder = '/kaggle/input/aiunict-2023/test'\n",
        "\n",
        "# path to new cropped images\n",
        "cropped_folder = '/kaggle/working/test'\n",
        "\n",
        "# create folders for cropped images if they don't exist\n",
        "if not os.path.exists(cropped_folder):\n",
        "    os.makedirs(cropped_folder)\n",
        "\n",
        "# loop through rows in the dataframe\n",
        "for index, row in df.iterrows():\n",
        "    # get image name and coordinates from dataframe\n",
        "    img_name = row['image']\n",
        "    x1, y1, x2, y2 = row['x1'], row['y1'], row['x2'], row['y2']\n",
        "    \n",
        "    if(x1 < 1):\n",
        "        continue\n",
        "\n",
        "        \n",
        "     # calculate center of bounding box\n",
        "    center_x = (x1 + x2) // 2\n",
        "    center_y = (y1 + y2) // 2\n",
        "    \n",
        "    # adjust coordinates for cropping\n",
        "    crop_width = int((x2 - x1) * 0.6)  # crop more than half of the image\n",
        "    crop_height = int((y2 - y1) * 0.6)  # crop more than half of the image\n",
        "    crop_x1 = center_x - crop_width // 2\n",
        "    crop_y1 = center_y - crop_height // 2\n",
        "    crop_x2 = center_x + crop_width // 2\n",
        "    crop_y2 = center_y + crop_height // 2   \n",
        "        \n",
        "        \n",
        "    # path to original image and new cropped image\n",
        "    img_path = os.path.join(img_folder, img_name)\n",
        "    cropped_path = os.path.join(cropped_folder)\n",
        "\n",
        "    # read original image and crop it\n",
        "    img = cv2.imread(img_path)\n",
        "    cropped_img = img[crop_y1:crop_y2, crop_x1:crop_x2]\n",
        "\n",
        "    # write cropped image to file\n",
        "    if not os.path.exists(cropped_path):\n",
        "        os.makedirs(cropped_path)\n",
        "    cv2.imwrite(os.path.join(cropped_path, img_name.split('/')[-1]), cropped_img)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "jaiZ8LIBMhWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process Image\n",
        "#image = process_image(\"/kaggle/input/aiunict-2023/test/450.jpg\")\n",
        "image = process_image(\"/kaggle/working/test/112.jpg\")\n",
        "\n",
        "# Give image to model to predict output\n",
        "model_ft = model_ft.to(\"cpu\")\n",
        "top_prob, top_class = predict(image, model_ft)\n",
        "top_prob = top_prob / 10\n",
        "# Show the image\n",
        "show_image(image)\n",
        "# Print the results\n",
        "print(\"The model is %.2f\" % top_prob, \"% certain that the image has a predicted class of \", top_class  )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-23T10:30:59.939823Z",
          "iopub.execute_input": "2023-05-23T10:30:59.940982Z",
          "iopub.status.idle": "2023-05-23T10:31:00.340256Z",
          "shell.execute_reply.started": "2023-05-23T10:30:59.940942Z",
          "shell.execute_reply": "2023-05-23T10:31:00.338684Z"
        },
        "trusted": true,
        "id": "V2IWrmP-MhWE",
        "outputId": "ac1978a4-ad78-4df0-b45f-d6f9cecbdf2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "The model is 56.31 % certain that the image has a predicted class of  0\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 2500x400 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the test dataset class\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, img_dir):\n",
        "        self.img_dir = img_dir\n",
        "        self.img_names = os.listdir(img_dir)\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = os.path.join(self.img_dir, self.img_names[index])\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img = self.transform(img)\n",
        "        return img, self.img_names[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_names)\n",
        "\n",
        "# Create a DataLoader for the test dataset\n",
        "test_dataset = TestDataset('/kaggle/working/test')\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "# Create a list to store the predicted outputs\n",
        "pred_outputs = []\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model_ft.eval()\n",
        "\n",
        "# Loop through the test DataLoader and get the predicted outputs\n",
        "with torch.no_grad():\n",
        "    for batch, (imgs, img_names) in enumerate(test_loader):\n",
        "        # Move inputs to device\n",
        "        imgs = imgs.to('cpu')\n",
        "\n",
        "        # Forward pass through the model\n",
        "        outputs = model_ft(imgs)\n",
        "\n",
        "        # Get the predicted class index\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        # Append the predicted outputs to your list\n",
        "        for i in range(len(preds)):\n",
        "            pred_outputs.append((img_names[i], preds[i].item()))\n",
        "            \n",
        "        print(pred_outputs)\n",
        "\n",
        "# Save the predicted outputs to a CSV file\n",
        "with open('submission.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(['image', 'class'])\n",
        "    for output in pred_outputs:\n",
        "        writer.writerow(output)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "6wSyiGVdMhWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Faster R-CNN Model"
      ],
      "metadata": {
        "id": "ZVcHtJS5RW1W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definitions\n"
      ],
      "metadata": {
        "id": "TVI-acCcUp3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Importing Libraries**"
      ],
      "metadata": {
        "id": "MvuPKeWoRs_r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45jwvizkRmlY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import cv2\n",
        "from xml.etree import ElementTree as et\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms as torchtrans  \n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from torch.utils.data import random_split\n",
        "from matplotlib import pyplot as plt\n",
        "from numpy import asarray\n",
        "from torchmetrics.classification import Accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Custom Dataset**"
      ],
      "metadata": {
        "id": "VgHRajr3SAgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, root_dir, train=True,mask=False, transforms=None):\n",
        "        self.split = \"train\" if train else \"test\"\n",
        "        self.root_dir = Path(root_dir)/self.split\n",
        "        self.transforms = transforms\n",
        "        self.files = []\n",
        "        self.mask=mask\n",
        "        self.df_mask=pd.DataFrame()\n",
        "        folders = sorted(os.listdir(self.root_dir))\n",
        "        \n",
        "        if self.split==\"train\" :\n",
        "            if  mask:\n",
        "                self.df_mask=pd.read_csv(root_dir+\"train.csv\")\n",
        "            for folder in folders:\n",
        "                class_idx= folders.index(folder)\n",
        "                folder_dir = self.root_dir/folder\n",
        "                files = os.listdir(folder_dir)\n",
        "                if(class_idx==0):\n",
        "                    for x in files:\n",
        "                        self.files.append({\"mask\":folder+\"/\"+x,\"file\": folder_dir/x, \"class\": class_idx+1,\"flag\":False})\n",
        "                else:\n",
        "                    for x in files:\n",
        "                        self.files.append({\"mask\":folder+\"/\"+x,\"file\": folder_dir/x, \"class\": class_idx+1,\"flag\":False})\n",
        "        else:\n",
        "            self.file=folders\n",
        "            for file in folders:\n",
        "                 self.files.append(self.root_dir/file)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        \n",
        "        if self.split == \"train\":\n",
        "            item = self.files[i]\n",
        "            file = item['file']\n",
        "            # reading the images and converting them to correct size and color    \n",
        "            img = cv2.imread(str(file))\n",
        "            img_res = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "            # diving by 255\n",
        "            img_res /= 255.0\n",
        "            # recover bounding boxes\n",
        "            name_file_img=item['mask']\n",
        "            mask_data=self.df_mask[self.df_mask[\"image\"]==name_file_img]\n",
        "            xmin=int(mask_data[\"x1\"])+1\n",
        "            ymin=int(mask_data[\"y1\"])+1\n",
        "            xmax=int(mask_data[\"x2\"])-1\n",
        "            ymax=int(mask_data[\"y2\"])-1\n",
        "            \n",
        "            # resize bounding boxes\n",
        "            boxes = []           \n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "            # convert boxes into a torch.Tensor\n",
        "            boxes = torch.as_tensor(boxes, dtype=torch.int64)            \n",
        "            labels = torch.tensor(item['class'],dtype=torch.int64)\n",
        "            labels=labels.unsqueeze(0)\n",
        "            \n",
        "            target = {}\n",
        "            target[\"boxes\"] = boxes\n",
        "            target[\"labels\"] = labels\n",
        "                        \n",
        "            if self.transforms:\n",
        "            \n",
        "                sample = {'image' : img_res,\n",
        "                          'bboxes' : target['boxes'],\n",
        "                          'labels' : labels\n",
        "                         }\n",
        "               \n",
        "                sample = self.transforms(**sample)\n",
        "                img_res = sample['image']\n",
        "                target['boxes'] = torch.as_tensor((sample['bboxes']),dtype=torch.int64)\n",
        "                \n",
        "               \n",
        "            return img_res, target\n",
        "        else:\n",
        "            file = self.files[i]\n",
        "            img = cv2.imread(str(file))\n",
        "            img_res = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "            img_res /= 255.0\n",
        "            \n",
        "            if self.transforms:\n",
        "                sample = {\n",
        "                    'image': img_res,\n",
        "                }\n",
        "                sample = self.transforms(**sample)\n",
        "                image = sample['image']\n",
        "                             \n",
        "            return image,self.file[i]"
      ],
      "metadata": {
        "id": "dNCiFpLqRpoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Transformations**"
      ],
      "metadata": {
        "id": "YEbAnFiuSMH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_transformations():\n",
        "    return A.Compose([\n",
        "        A.Flip(0.5),\n",
        "        A.ShiftScaleRotate(shift_limit=0.2,scale_limit=0.25, rotate_limit=45, p=0.7),        \n",
        "        ToTensorV2(p=1.0)\n",
        "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
        "\n",
        "def test_transformations():\n",
        "    return A.Compose([\n",
        "        ToTensorV2(p=1.0)\n",
        "    ])"
      ],
      "metadata": {
        "id": "M-HKo1CJRpqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "3YNpq6_xUliz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Dataloaders**"
      ],
      "metadata": {
        "id": "wsLYEdGBSVLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "root_dir = \"../input/aiunict-2023/\"\n",
        "train_dataset = MyDataset(root_dir, train=True,mask=True, transforms= train_transformations())\n",
        "train_data_loader = DataLoader(train_dataset,batch_size=8,shuffle=True,num_workers=4,collate_fn=collate_fn)\n"
      ],
      "metadata": {
        "id": "_BpICLC9RptF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing pretrained FasterRCNN Model**"
      ],
      "metadata": {
        "id": "YcwllYZJSfJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "classes_count = 9 \n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, classes_count)"
      ],
      "metadata": {
        "id": "ebPsy6tRRpvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Averager class to keep track of the average loss**"
      ],
      "metadata": {
        "id": "t8Ds7oKgTKl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Averager:\n",
        "    def __init__(self):\n",
        "        self.current_total = 0.0\n",
        "        self.iterations = 0.0\n",
        "\n",
        "    def send(self, value):\n",
        "        self.current_total += value\n",
        "        self.iterations += 1\n",
        "\n",
        "    @property\n",
        "    def value(self):\n",
        "        if self.iterations == 0:\n",
        "            return 0\n",
        "        else:\n",
        "            return 1.0 * self.current_total / self.iterations\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_total = 0.0\n",
        "        self.iterations = 0.0"
      ],
      "metadata": {
        "id": "vhwIrySbRpxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining NMS technique to improve the results**"
      ],
      "metadata": {
        "id": "qn77k2itTw-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_nms(orig_prediction, iou_thresh=0.3):\n",
        "    keep = torchvision.ops.nms(orig_prediction['boxes'], orig_prediction['scores'], iou_thresh)\n",
        "    final_prediction = orig_prediction\n",
        "    final_prediction['boxes'] = final_prediction['boxes'][keep]\n",
        "    final_prediction['scores'] = final_prediction['scores'][keep]\n",
        "    final_prediction['labels'] = final_prediction['labels'][keep]\n",
        "    \n",
        "    return final_prediction"
      ],
      "metadata": {
        "id": "xBr4xlGJRpzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting parameters**"
      ],
      "metadata": {
        "id": "p7ZOQDnhUNPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0001)\n",
        "lr_scheduler =None"
      ],
      "metadata": {
        "id": "V-pWnZHfRp11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Loop**"
      ],
      "metadata": {
        "id": "0ipKyqi7UWvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs =  10 \n",
        "loss_hist = Averager()\n",
        "itr = 1\n",
        "lossHistoryiter = []\n",
        "lossHistoryepoch = []\n",
        "true_lab=[]\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    loss_hist.reset()\n",
        "    model.train()\n",
        "    for images, targets in train_data_loader:\n",
        "        \n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        loss_dict = model(images, targets)  \n",
        "        \n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        loss_value = losses.item()\n",
        "        \n",
        "        loss_hist.send(loss_value)\n",
        "        lossHistoryiter.append(loss_value)\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if itr % 50 == 0:\n",
        "            print(f\"Iteration #{itr} loss: {loss_value}\")\n",
        "\n",
        "        itr += 1\n",
        "    \n",
        "    lossHistoryepoch.append(loss_hist.value)\n",
        "    print(f\"Epoch #{epoch} loss: {loss_hist.value}\")\n",
        "     \n",
        "end = time.time()\n",
        "hours, rem = divmod(end-start, 3600)\n",
        "minutes, seconds = divmod(rem, 60)\n",
        "print(\"Time taken to Train the model :{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
      ],
      "metadata": {
        "id": "3dLn_vDTTR74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "w8tu0E5EUcpZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Test Dataset**"
      ],
      "metadata": {
        "id": "1Haz9tXZUxS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = MyDataset(root_dir, train=False, transforms= test_transformations())"
      ],
      "metadata": {
        "id": "XiH8V__DTR5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running the model on the test dataset and saving the CSV file**"
      ],
      "metadata": {
        "id": "DIdP5anFU4tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_list=[]\n",
        "class_list=[]\n",
        "for idx in range(test_dataset.__len__()):\n",
        "    img,name_file = test_dataset[idx]\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        prediction = model([img.to(device)])[0]\n",
        "    nms_prediction = apply_nms(prediction, iou_thresh=0.2)\n",
        "    pred=nms_prediction['labels'].cpu().numpy()[0]\n",
        "    \n",
        "    image_list.append(name_file)\n",
        "    class_list.append(pred-1)\n",
        "    \n",
        "d = {'image': image_list, 'class': class_list}\n",
        "df = pd.DataFrame(data=d)\n",
        "df.to_csv(\"submission.csv\",index=False)"
      ],
      "metadata": {
        "id": "lKCj-_QJTR24"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}