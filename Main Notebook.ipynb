{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Definitions\n"
      ],
      "metadata": {
        "id": "TVI-acCcUp3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Importing Libraries**"
      ],
      "metadata": {
        "id": "MvuPKeWoRs_r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45jwvizkRmlY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import cv2\n",
        "from xml.etree import ElementTree as et\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms as torchtrans  \n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from torch.utils.data import random_split\n",
        "from matplotlib import pyplot as plt\n",
        "from numpy import asarray\n",
        "from torchmetrics.classification import Accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Custom Dataset**"
      ],
      "metadata": {
        "id": "VgHRajr3SAgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, root_dir, train=True,mask=False, transforms=None):\n",
        "        self.split = \"train\" if train else \"test\"\n",
        "        self.root_dir = Path(root_dir)/self.split\n",
        "        self.transforms = transforms\n",
        "        self.files = []\n",
        "        self.mask=mask\n",
        "        self.df_mask=pd.DataFrame()\n",
        "        folders = sorted(os.listdir(self.root_dir))\n",
        "        \n",
        "        if self.split==\"train\" :\n",
        "            if  mask:\n",
        "                self.df_mask=pd.read_csv(root_dir+\"train.csv\")\n",
        "            for folder in folders:\n",
        "                class_idx= folders.index(folder)\n",
        "                folder_dir = self.root_dir/folder\n",
        "                files = os.listdir(folder_dir)\n",
        "                if(class_idx==0):\n",
        "                    for x in files:\n",
        "                        self.files.append({\"mask\":folder+\"/\"+x,\"file\": folder_dir/x, \"class\": class_idx+1,\"flag\":False})\n",
        "                else:\n",
        "                    for x in files:\n",
        "                        self.files.append({\"mask\":folder+\"/\"+x,\"file\": folder_dir/x, \"class\": class_idx+1,\"flag\":False})\n",
        "        else:\n",
        "            self.file=folders\n",
        "            for file in folders:\n",
        "                 self.files.append(self.root_dir/file)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        \n",
        "        if self.split == \"train\":\n",
        "            item = self.files[i]\n",
        "            file = item['file']\n",
        "            # reading the images and converting them to correct size and color    \n",
        "            img = cv2.imread(str(file))\n",
        "            img_res = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "            # diving by 255\n",
        "            img_res /= 255.0\n",
        "            # recover bounding boxes\n",
        "            name_file_img=item['mask']\n",
        "            mask_data=self.df_mask[self.df_mask[\"image\"]==name_file_img]\n",
        "            xmin=int(mask_data[\"x1\"])+1\n",
        "            ymin=int(mask_data[\"y1\"])+1\n",
        "            xmax=int(mask_data[\"x2\"])-1\n",
        "            ymax=int(mask_data[\"y2\"])-1\n",
        "            \n",
        "            # resize bounding boxes\n",
        "            boxes = []           \n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "            # convert boxes into a torch.Tensor\n",
        "            boxes = torch.as_tensor(boxes, dtype=torch.int64)            \n",
        "            labels = torch.tensor(item['class'],dtype=torch.int64)\n",
        "            labels=labels.unsqueeze(0)\n",
        "            \n",
        "            target = {}\n",
        "            target[\"boxes\"] = boxes\n",
        "            target[\"labels\"] = labels\n",
        "                        \n",
        "            if self.transforms:\n",
        "            \n",
        "                sample = {'image' : img_res,\n",
        "                          'bboxes' : target['boxes'],\n",
        "                          'labels' : labels\n",
        "                         }\n",
        "               \n",
        "                sample = self.transforms(**sample)\n",
        "                img_res = sample['image']\n",
        "                target['boxes'] = torch.as_tensor((sample['bboxes']),dtype=torch.int64)\n",
        "                \n",
        "               \n",
        "            return img_res, target\n",
        "        else:\n",
        "            file = self.files[i]\n",
        "            img = cv2.imread(str(file))\n",
        "            img_res = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "            img_res /= 255.0\n",
        "            \n",
        "            if self.transforms:\n",
        "                sample = {\n",
        "                    'image': img_res,\n",
        "                }\n",
        "                sample = self.transforms(**sample)\n",
        "                image = sample['image']\n",
        "                             \n",
        "            return image,self.file[i]"
      ],
      "metadata": {
        "id": "dNCiFpLqRpoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Transformations**"
      ],
      "metadata": {
        "id": "YEbAnFiuSMH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_transformations():\n",
        "    return A.Compose([\n",
        "        A.Flip(0.5),\n",
        "        A.ShiftScaleRotate(shift_limit=0.2,scale_limit=0.25, rotate_limit=45, p=0.7),        \n",
        "        ToTensorV2(p=1.0)\n",
        "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
        "\n",
        "def test_transformations():\n",
        "    return A.Compose([\n",
        "        ToTensorV2(p=1.0)\n",
        "    ])"
      ],
      "metadata": {
        "id": "M-HKo1CJRpqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "3YNpq6_xUliz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Dataloaders**"
      ],
      "metadata": {
        "id": "wsLYEdGBSVLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "root_dir = \"../input/aiunict-2023/\"\n",
        "train_dataset = MyDataset(root_dir, train=True,mask=True, transforms= train_transformations())\n",
        "train_data_loader = DataLoader(train_dataset,batch_size=8,shuffle=True,num_workers=4,collate_fn=collate_fn)\n"
      ],
      "metadata": {
        "id": "_BpICLC9RptF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing pretrained FasterRCNN Model**"
      ],
      "metadata": {
        "id": "YcwllYZJSfJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "classes_count = 9 \n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, classes_count)"
      ],
      "metadata": {
        "id": "ebPsy6tRRpvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Averager class to keep track of the average loss**"
      ],
      "metadata": {
        "id": "t8Ds7oKgTKl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Averager:\n",
        "    def __init__(self):\n",
        "        self.current_total = 0.0\n",
        "        self.iterations = 0.0\n",
        "\n",
        "    def send(self, value):\n",
        "        self.current_total += value\n",
        "        self.iterations += 1\n",
        "\n",
        "    @property\n",
        "    def value(self):\n",
        "        if self.iterations == 0:\n",
        "            return 0\n",
        "        else:\n",
        "            return 1.0 * self.current_total / self.iterations\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_total = 0.0\n",
        "        self.iterations = 0.0"
      ],
      "metadata": {
        "id": "vhwIrySbRpxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining NMS technique to improve the results**"
      ],
      "metadata": {
        "id": "qn77k2itTw-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_nms(orig_prediction, iou_thresh=0.3):\n",
        "    keep = torchvision.ops.nms(orig_prediction['boxes'], orig_prediction['scores'], iou_thresh)\n",
        "    final_prediction = orig_prediction\n",
        "    final_prediction['boxes'] = final_prediction['boxes'][keep]\n",
        "    final_prediction['scores'] = final_prediction['scores'][keep]\n",
        "    final_prediction['labels'] = final_prediction['labels'][keep]\n",
        "    \n",
        "    return final_prediction"
      ],
      "metadata": {
        "id": "xBr4xlGJRpzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting parameters**"
      ],
      "metadata": {
        "id": "p7ZOQDnhUNPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0001)\n",
        "lr_scheduler =None"
      ],
      "metadata": {
        "id": "V-pWnZHfRp11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Loop**"
      ],
      "metadata": {
        "id": "0ipKyqi7UWvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs =  10 \n",
        "loss_hist = Averager()\n",
        "itr = 1\n",
        "lossHistoryiter = []\n",
        "lossHistoryepoch = []\n",
        "true_lab=[]\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    loss_hist.reset()\n",
        "    model.train()\n",
        "    for images, targets in train_data_loader:\n",
        "        \n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        loss_dict = model(images, targets)  \n",
        "        \n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        loss_value = losses.item()\n",
        "        \n",
        "        loss_hist.send(loss_value)\n",
        "        lossHistoryiter.append(loss_value)\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if itr % 50 == 0:\n",
        "            print(f\"Iteration #{itr} loss: {loss_value}\")\n",
        "\n",
        "        itr += 1\n",
        "    \n",
        "    lossHistoryepoch.append(loss_hist.value)\n",
        "    print(f\"Epoch #{epoch} loss: {loss_hist.value}\")\n",
        "     \n",
        "end = time.time()\n",
        "hours, rem = divmod(end-start, 3600)\n",
        "minutes, seconds = divmod(rem, 60)\n",
        "print(\"Time taken to Train the model :{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
      ],
      "metadata": {
        "id": "3dLn_vDTTR74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "w8tu0E5EUcpZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Test Dataset**"
      ],
      "metadata": {
        "id": "1Haz9tXZUxS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = MyDataset(root_dir, train=False, transforms= test_transformations())"
      ],
      "metadata": {
        "id": "XiH8V__DTR5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running the model on the test dataset and saving the CSV file**"
      ],
      "metadata": {
        "id": "DIdP5anFU4tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_list=[]\n",
        "class_list=[]\n",
        "for idx in range(test_dataset.__len__()):\n",
        "    img,name_file = test_dataset[idx]\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        prediction = model([img.to(device)])[0]\n",
        "    nms_prediction = apply_nms(prediction, iou_thresh=0.2)\n",
        "    pred=nms_prediction['labels'].cpu().numpy()[0]\n",
        "    \n",
        "    image_list.append(name_file)\n",
        "    class_list.append(pred-1)\n",
        "    \n",
        "d = {'image': image_list, 'class': class_list}\n",
        "df = pd.DataFrame(data=d)\n",
        "df.to_csv(\"submission.csv\",index=False)"
      ],
      "metadata": {
        "id": "lKCj-_QJTR24"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
